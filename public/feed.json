{
  "version": "https://jsonfeed.org/version/1",
  "title": "François Petitit",
  "home_page_url": "https://francoispetitit.com/",
  "feed_url": "https://francoispetitit.com/feed.json",
  "description": "François Petitit",
  "favicon": "https://francoispetitit.com//assets/favicon.ico",
  "expired": false,
  "author": {
    "name": "François Petitit",
    "url": "https://francoispetitit.com/"
  },
  "items": [
    
    

    
    {
      "id": "591b634b08647f3f8671602f1c2bc9545248743c",
      "title": "IA - the Beginning of the End of the Party ?",
      "summary": "",
      "content_text": "I learned this morning that Stability AI, the company that develops and operates the Stable Diffusion image generator, is in financial trouble:\nhttps://www.theregister.com/2024/04/03/stability_ai_bills/\nOn the face of it, the reason is simple: to generate images via AI, you need a lot of calculations, and therefore a lot of GPUs. And that\u0026rsquo;s expensive. Very expensive: $99 million per year, according to the article. And generative AI, which can generate images and videos, currently generates very little revenue. 11 million, according to the article. And not enough funds have been raised.\nApparently, management has been completely renewed, and all is not lost for Stability AI.\nNevertheless, when I step back and ask myself the question of financing these mega infrastructures, I ask myself this question:\nIs this the end of the first phase of generative AI, that of pure innovation, and the beginning of rationalization?\nAnd for the end-users that we all are, perhaps the end of free services\u0026hellip;\n",
      "content_html": "\u003cp\u003eI learned this morning that Stability AI, the company that develops and operates the Stable Diffusion image generator, is in financial trouble:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.theregister.com/2024/04/03/stability_ai_bills/\"\u003ehttps://www.theregister.com/2024/04/03/stability_ai_bills/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eOn the face of it, the reason is simple: to generate images via AI, you need a lot of calculations, and therefore a lot of GPUs.\nAnd that\u0026rsquo;s expensive. Very expensive: $99 million per year, according to the article.\nAnd generative AI, which can generate images and videos, currently generates very little revenue. 11 million, according to the article. And not enough funds have been raised.\u003c/p\u003e\n\u003cp\u003eApparently, management has been completely renewed, and all is not lost for Stability AI.\u003c/p\u003e\n\u003cp\u003eNevertheless, when I step back and ask myself the question of financing these mega infrastructures, I ask myself this question:\u003c/p\u003e\n\u003cp\u003eIs this the \u003cem\u003eend of the first phase of generative AI, that of pure innovation\u003c/em\u003e, and the \u003cem\u003ebeginning of rationalization\u003c/em\u003e?\u003c/p\u003e\n\u003cp\u003eAnd for the end-users that we all are, perhaps the end of free services\u0026hellip;\u003c/p\u003e\n",
      "url": "https://francoispetitit.com/posts/ia-the-beginning-of-the-end-of-the-party/",
      "date_published": "5046-05-09T448:55:00+02:00",
      "date_modified": "5046-05-09T448:55:00+02:00",
      "author": {
        "name": "François Petitit",
        "url": "https://francoispetitit.com/"
      }
    },
    
    {
      "id": "1171f431f5f01c5079e9df9d8a79533809931408",
      "title": "Writing a New Blog With Hugo",
      "summary": "",
      "content_text": "As you can see from this post, I\u0026rsquo;ve just launched a new blog.\nIt already includes a few old articles published elsewhere, here and there, and I\u0026rsquo;ll try to publish new ones regularly.\nBut let\u0026rsquo;s get technical !\nThis blog has been developed using the following tools:\nHugo as the blog engine: https://gohugo.io/ Github to store the code, compile the production version and deploy on Github Pages . You can take a look at the source code here : https://github.com/fpetitit/blog OVH Cloud to manage the domain name Why did I choose Hugo? There are a huge number of blog generation tools available. For example, I used Jekyll for a long time for similar purposes. I\u0026rsquo;m also inevitably thinking of Wordpress, which is heavy and complex but still a potential alternative, and which still adds a lot of possibilities.\nFinally, I chose Hugo mainly because a web design site that I\u0026rsquo;ve been following closely for years recently made this choice. It\u0026rsquo;s Smashing Magazine, and they detail their migration in an article : https://www.smashingmagazine.com/2019/05/switch-wordpress-hugo/.\nWell, OK, since then they\u0026rsquo;ve switched to TinyCMS. But TinyCMS was far too heavy for my little blog ;)\n",
      "content_html": "\u003cp\u003eAs you can see from this post, I\u0026rsquo;ve just launched a new blog.\u003c/p\u003e\n\u003cp\u003eIt already includes a few old articles published elsewhere, here and there, and I\u0026rsquo;ll try to publish new ones regularly.\u003c/p\u003e\n\u003cp\u003eBut let\u0026rsquo;s get technical !\u003c/p\u003e\n\u003cp\u003eThis blog has been developed using the following tools:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eHugo as the blog engine: \u003ca href=\"https://gohugo.io/\"\u003ehttps://gohugo.io/\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eGithub to store the code, compile the production version and deploy on Github Pages . You can take a look at the source code here : \u003ca href=\"https://github.com/fpetitit/blog\"\u003ehttps://github.com/fpetitit/blog\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.ovhcloud.com/fr/\"\u003eOVH Cloud\u003c/a\u003e to manage the domain name\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"why-did-i-choose-hugo\"\u003eWhy did I choose Hugo?\u003c/h2\u003e\n\u003cp\u003eThere are a huge number of blog generation tools available. For example, I used \u003ca href=\"https://jekyllrb.com/\"\u003eJekyll\u003c/a\u003e for a long time for similar purposes.\nI\u0026rsquo;m also inevitably thinking of Wordpress, which is heavy and complex but still a potential alternative, and which still adds a lot of possibilities.\u003c/p\u003e\n\u003cp\u003eFinally, I chose Hugo mainly because a web design site that I\u0026rsquo;ve been following closely for years recently made this choice.\nIt\u0026rsquo;s Smashing Magazine, and they detail their migration in an article : \u003ca href=\"https://www.smashingmagazine.com/2019/05/switch-wordpress-hugo/\"\u003ehttps://www.smashingmagazine.com/2019/05/switch-wordpress-hugo/\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eWell, OK, since then they\u0026rsquo;ve switched to TinyCMS. But TinyCMS was far too heavy for my little blog ;)\u003c/p\u003e\n",
      "url": "https://francoispetitit.com/posts/writing-a-new-blog-with-hugo/",
      "date_published": "4046-04-09T437:44:00+02:00",
      "date_modified": "4046-04-09T437:44:00+02:00",
      "author": {
        "name": "François Petitit",
        "url": "https://francoispetitit.com/"
      }
    },
    
    {
      "id": "ddab5ff15afb8acd087338c06d0e5c19e22f1dee",
      "title": "How We Used React Virtualized to Boost Our Sale Page",
      "summary": "",
      "content_text": "This article was previously published here : https://medium.com/la-ruche-qui-dit-oui/how-we-used-react-virtualized-to-boost-our-sale-page-6e2f087039ca\nHow we used React Virtualized to boost our sale page Our mission at La Ruche qui dit Oui ! is to provide good and fair products to our customers, directly from farmers and craftsmen.\nSince last year, we have been working to improve and expand our product offerings, bringing more and more producers and more and more products to our customers.\nChallenges arise at many levels: logistics, communication, marketing, but also the user experience offered by our website.\nThis article focuses on what we did, as Web developers, to handle more and more farmers and more and more products on our new sale page :\nBut before getting to the code, let’s see what we wanted to change on this page.\nThe old sale page: why we chose to abandon it The sale page looked like that, until the last few weeks:\nWhen this page was designed and implemented, there were only dozens or a few hundreds products per sale. It worked fine at the beginning, but as the number of offers was growing up, we identified some limitations that were problematic:\na fundamental pattern of our navigation wasn’t understood by the user, especially the newcomers: the products are ordered by farms (because we want to highlight our farmers). Some users dropped their orders or had to spend more time to compare the products, and as you know, on a e-commerce website, more time means less sales… on iOS devices, the browser crashed when there were too many products — due to a lack of memory. We used a pagination but it made the sale harder to navigate. on large screens, the products were also displayed by batches of 20: when the user was coming to a category, the first 20 were displayed, then when the user scrolled to the bottom, the next 20 were added at the bottom of the list, and so on. Fast scrolling navigation was a bit jerky. on large screen, the page didn’t use all the width of the page: it was a shame because we could have displayed more products. access to categories, subcategories and organic filters was only possible when the user was on top of the page. Discovering the whole range of products was not easy and organic filters deserved to be more visible. So, we needed to improve the discoverability of the whole catalog, and the navigation inside it.\nAfter a few weeks of user testing and design adjustments, we finally decided to implement this new page:\nThe main technical challenge of the new sale page was the “all products” category:\nAs you may guess viewing the screenshot, there are now 2 ways to navigate inside a category:\nthe user can scroll into the products list, from the first product to the last one (sometimes there are more than 2000 products). or the user can click on a farm in the farms list on the left side: the list will automatically scroll up or down to the first product of the farmer. So, let’s see how we handled displaying long lists and browsing into them in our code.\nHandle long list with React : React-virtualized At La Ruche qui dit Oui !, we chose about 2 years ago to develop all our new Web front-end features with React.\nReact is very powerful to manipulate the DOM efficiently thanks to its use of shadow DOM. We aim to provide the most fluid and responsive interfaces thanks to React.\nIn its documentation, React provides some guidelines to optimize performances. In particular, there is a paragraph about “Virtualize Long Lists” :\nVirtualize Long Lists\nIf your application renders long lists of data (hundreds or thousands of rows), we recommended using a technique known as “windowing”. This technique only renders a small subset of your rows at any given time, and can dramatically reduce the time it takes to re-render the components as well as the number of DOM nodes created.\nReact Virtualized is one popular windowing library. It provides several reusable components for displaying lists, grids, and tabular data. You can also create your own windowing component, like Twitter did, if you want something more tailored to your application’s specific use case.\nWindowing is pretty easy to understand with the capture below, displaying the content of the DOM at a precise moment : only a dozen of rows are rendered into the DOM, no matter the total number of rows. React Virtualized will remove the rows that are no longer visible and add the newly visible each time the user scrolls into the page.\nSo as the documentation mentioned React Virtualized, and as it seemed to handle our use cases, we chose to use it to implement the new features.\nHow we use React Virtualized We managed to isolate all our usage of React Virtualized in only one component, called “ProductsList.jsx”.\nFinally, we used 2 components from the library: List and WindowScroller. Our imports look like this:\nNote that the explicit path used in the import directives are due to the recommendation from here and could be removed if you’re using Webpack 4.\nList allows to display a windowed list of elements.\nWindowScroller allows the List component to be scrolled based on the window\u0026rsquo;s scroll positions. Also, the scrollbar will reflect the length of the list and the current position.\nNow let’s render these components in the render function of our ProductsList component:\nThe properties passed to the List component can be divided in 3 parts: the content of the list, the dimensions of the list, and handling the user interactions.\n###The content of the list\nGiving the content is done by passing a function as the rowRenderer property, that will return the React component corresponding to the index of the desired row:\n(R is for RamdaJS)\nWhere farmsAndProductsComponents is a pre-computed array that contains React components displaying either a farmer card or a product card. This part of the code is pretty obvious, but will be complicated to handle the dimension of the list.\nHandling the dimension of the list One of the key thing that must be done to handle the scrollbar of the window is to be able to know the size of the entire list.\nSo we set fixed height to our components, according to their types (farmer card or product card) and the width of the window (the cards heights are bigger on small screen than on large screen), and passed the function as the rowHeight prop:\nHandling the user interaction If we stopped here, the user could scroll into the list, use the scrollbar, and know where it situated into the list.\nBut we wanted to provide an other way to navigate, by displaying the list of the producers, displaying the current producer (the one corresponding to the first visible product in the screen), and going to an other producer by clicking on its name. This is the purpose of the menu on the left side, in large screen:\nThe producers list in the sticky menu\nDisplaying the current farm To do that, we added a “scrollY” attribute to our list components:\nIt allowed us to determine the current producer by looking for the first element of the list having a scrollY visible according to window.pageYOffset:\nGoing to a specific producer Finally, going to a specific producer was done by calculating the position of the producer card by accumulating the heights of the previous components from the list and scrolling to the position:\nConclusion : the pros and cons of React Virtualized We are quite happy of our new sale page and React Virtualized was really a great tool to help use prototyping and developing all the features that we wanted.\nThe performance are very good, it works well on all the browsers that we support, especially on the most difficult to support for us which are IE 11 and Safari Mobile on relatively old iOS devices.\nWe were concerned by 2 problems until now. Both are due to the fact that the whole list is never present into the DOM:\nsearching into the list by the find function of the browsers (“ctrl + f”) is working only in the visible rows, but we provide a Search functionality in the sale page that the user should use instead of the browser’s function, and that provides more intelligent results some CSS rules cannot be used, for example selectors like first-of-type If you have faced challenges of the same type, please share your experiences in the comments of this blog post :)\n",
      "content_html": "\u003cp\u003eThis article was previously published here : \u003ca href=\"https://medium.com/la-ruche-qui-dit-oui/how-we-used-react-virtualized-to-boost-our-sale-page-6e2f087039ca\"\u003ehttps://medium.com/la-ruche-qui-dit-oui/how-we-used-react-virtualized-to-boost-our-sale-page-6e2f087039ca\u003c/a\u003e\u003c/p\u003e\n\u003ch1 id=\"how-we-used-react-virtualized-to-boost-our-sale-page\"\u003eHow we used React Virtualized to boost our sale page\u003c/h1\u003e\n\u003cp\u003eOur mission at \u003ca href=\"https://laruchequiditoui.fr/fr\"\u003eLa Ruche qui dit Oui !\u003c/a\u003e is to provide good and fair products to our customers, directly from farmers and craftsmen.\u003c/p\u003e\n\u003cp\u003eSince last year, we have been working to improve and expand our product offerings, bringing more and more producers and more and more products to our customers.\u003c/p\u003e\n\u003cp\u003eChallenges arise at many levels: logistics, communication, marketing, but also the user experience offered by our website.\u003c/p\u003e\n\u003cp\u003eThis article focuses on what we did, as Web developers, to handle more and more farmers and more and more products on our new sale page :\u003c/p\u003e\n\u003cp\u003e\u003cimg\n  src=\"image.png\"\n  alt=\"Our new sale page\"\n  loading=\"lazy\"\n  decoding=\"async\"\n  class=\"full-width\"\n/\u003e\n\n\u003c/p\u003e\n\u003cp\u003eBut before getting to the code, let’s see what we wanted to change on this page.\u003c/p\u003e\n\u003ch2 id=\"the-old-sale-page-why-we-chose-to-abandon-it\"\u003eThe old sale page: why we chose to abandon it\u003c/h2\u003e\n\u003cp\u003eThe sale page looked like that, until the last few weeks:\u003c/p\u003e\n\u003cp\u003e\u003cimg\n  src=\"image-1.png\"\n  alt=\"Farewell, old page\"\n  loading=\"lazy\"\n  decoding=\"async\"\n  class=\"full-width\"\n/\u003e\n\n\u003c/p\u003e\n\u003cp\u003eWhen this page was designed and implemented, there were only dozens or a few hundreds products per sale. It worked fine at the beginning, but as the number of offers was growing up, we identified some limitations that were problematic:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ea fundamental pattern of our navigation wasn’t understood by the user, especially the newcomers: the products are ordered by farms (because we want to highlight our farmers). Some users dropped their orders or had to spend more time to compare the products, and as you know, on a e-commerce website, more time means less sales…\u003c/li\u003e\n\u003cli\u003eon iOS devices, the browser crashed when there were too many products — due to a lack of memory. We used a pagination but it made the sale harder to navigate.\u003c/li\u003e\n\u003cli\u003eon large screens, the products were also displayed by batches of 20: when the user was coming to a category, the first 20 were displayed, then when the user scrolled to the bottom, the next 20 were added at the bottom of the list, and so on. Fast scrolling navigation was a bit jerky.\u003c/li\u003e\n\u003cli\u003eon large screen, the page didn’t use all the width of the page: it was a shame because we could have displayed more products.\u003c/li\u003e\n\u003cli\u003eaccess to categories, subcategories and organic filters was only possible when the user was on top of the page. Discovering the whole range of products was not easy and organic filters deserved to be more visible.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSo, we needed to improve the discoverability of the whole catalog, and the navigation inside it.\u003c/p\u003e\n\u003cp\u003eAfter a few weeks of user testing and design adjustments, we finally decided to implement this new page:\u003c/p\u003e\n\u003cp\u003e\u003cimg\n  src=\"image-2.png\"\n  alt=\"The home screen of the new sale page : a selection of products\"\n  loading=\"lazy\"\n  decoding=\"async\"\n  class=\"full-width\"\n/\u003e\n\n\u003c/p\u003e\n\u003cp\u003eThe main technical challenge of the new sale page was the “all products” category:\u003c/p\u003e\n\u003cp\u003e\u003cimg\n  src=\"image-3.png\"\n  alt=\"The “All products” category\"\n  loading=\"lazy\"\n  decoding=\"async\"\n  class=\"full-width\"\n/\u003e\n\n\u003c/p\u003e\n\u003cp\u003eAs you may guess viewing the screenshot, there are now 2 ways to navigate inside a category:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ethe user can scroll into the products list, from the first product to the last one (sometimes there are more than 2000 products).\u003c/li\u003e\n\u003cli\u003eor the user can click on a farm in the farms list on the left side: the list will automatically scroll up or down to the first product of the farmer.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSo, let’s see how we handled displaying long lists and browsing into them in our code.\u003c/p\u003e\n\u003ch2 id=\"handle-long-list-with-react--react-virtualized\"\u003eHandle long list with React : React-virtualized\u003c/h2\u003e\n\u003cp\u003eAt La Ruche qui dit Oui !, we chose about 2 years ago to develop all our new Web front-end features with React.\u003c/p\u003e\n\u003cp\u003eReact is very powerful to manipulate the DOM efficiently thanks to its use of shadow DOM. We aim to provide the most fluid and responsive interfaces thanks to React.\u003c/p\u003e\n\u003cp\u003eIn its documentation, React provides some guidelines to optimize performances. In particular, there is a paragraph about “Virtualize Long Lists” :\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eVirtualize Long Lists\u003c/p\u003e\n\u003cp\u003eIf your application renders long lists of data (hundreds or thousands of rows), we recommended using a technique known as “windowing”. This technique only renders a small subset of your rows at any given time, and can dramatically reduce the time it takes to re-render the components as well as the number of DOM nodes created.\u003c/p\u003e\n\u003cp\u003eReact Virtualized is one popular windowing library. It provides several reusable components for displaying lists, grids, and tabular data. You can also create your own windowing component, like Twitter did, if you want something more tailored to your application’s specific use case.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eWindowing is pretty easy to understand with the capture below, displaying the content of the DOM at a precise moment : only a dozen of rows are rendered into the DOM, no matter the total number of rows. React Virtualized will remove the rows that are no longer visible and add the newly visible each time the user scrolls into the page.\u003c/p\u003e\n\u003cp\u003e\u003cimg\n  src=\"image-4.png\"\n  alt=\"At every moment, only a subset of the whole list is present in the DOM\"\n  loading=\"lazy\"\n  decoding=\"async\"\n  class=\"full-width\"\n/\u003e\n\n\u003c/p\u003e\n\u003cp\u003eSo as the documentation mentioned React Virtualized, and as it seemed to handle our use cases, we chose to use it to implement the new features.\u003c/p\u003e\n\u003ch2 id=\"how-we-use-react-virtualized\"\u003eHow we use React Virtualized\u003c/h2\u003e\n\u003cp\u003eWe managed to isolate all our usage of React Virtualized in only one component, called “ProductsList.jsx”.\u003c/p\u003e\n\u003cp\u003eFinally, we used 2 components from the library: List and WindowScroller. Our imports look like this:\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/fpetitit/775ba62467c257c737f4d413902ab5ab.js\"\u003e\u003c/script\u003e\n\u003cp\u003eNote that the explicit path used in the import directives are due to the recommendation from \u003ca href=\"https://medium.com/la-ruche-qui-dit-oui/how-we-used-react-virtualized-to-boost-our-sale-page-6e2f087039ca#:~:text=the%20recommendation%20from-,here,-and%20could%20be\"\u003ehere\u003c/a\u003e and could be removed if you’re using Webpack 4.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eList\u003c/code\u003e allows to display a windowed list of elements.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eWindowScroller\u003c/code\u003e allows the \u003ccode\u003eList\u003c/code\u003e component to be scrolled based on the window\u0026rsquo;s scroll positions. Also, the scrollbar will reflect the length of the list and the current position.\u003c/p\u003e\n\u003cp\u003eNow let’s render these components in the \u003ccode\u003erender\u003c/code\u003e function of our \u003ccode\u003eProductsList\u003c/code\u003e component:\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/fpetitit/79e217389fb23d42d0789bdedcee53cf.js\"\u003e\u003c/script\u003e\n\u003cp\u003eThe properties passed to the List component can be divided in 3 parts: the content of the list, the dimensions of the list, and handling the user interactions.\u003c/p\u003e\n\u003cp\u003e###The content of the list\u003c/p\u003e\n\u003cp\u003eGiving the content is done by passing a function as the rowRenderer property, that will return the React component corresponding to the index of the desired row:\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/fpetitit/499eb8cbe1b32ebef85251b9d6598196.js\"\u003e\u003c/script\u003e\n\u003cp\u003e(R is for \u003ca href=\"http://ramdajs.com/\"\u003eRamdaJS\u003c/a\u003e)\u003c/p\u003e\n\u003cp\u003eWhere farmsAndProductsComponents is a pre-computed array that contains React components displaying either a farmer card or a product card. This part of the code is pretty obvious, but will be complicated to handle the dimension of the list.\u003c/p\u003e\n\u003ch3 id=\"handling-the-dimension-of-the-list\"\u003eHandling the dimension of the list\u003c/h3\u003e\n\u003cp\u003eOne of the key thing that must be done to handle the scrollbar of the window is to be able to know the size of the entire list.\u003c/p\u003e\n\u003cp\u003eSo we set fixed height to our components, according to their types (farmer card or product card) and the width of the window (the cards heights are bigger on small screen than on large screen), and passed the function as the rowHeight prop:\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/fpetitit/5f94f76477670b6db561fb1f885509f7.js\"\u003e\u003c/script\u003e\n\u003ch3 id=\"handling-the-user-interaction\"\u003eHandling the user interaction\u003c/h3\u003e\n\u003cp\u003eIf we stopped here, the user could scroll into the list, use the scrollbar, and know where it situated into the list.\u003c/p\u003e\n\u003cp\u003eBut we wanted to provide an other way to navigate, by displaying the list of the producers, displaying the current producer (the one corresponding to the first visible product in the screen), and going to an other producer by clicking on its name. This is the purpose of the menu on the left side, in large screen:\u003c/p\u003e\n\u003cp\u003e\u003cimg\n  src=\"image-5.png\"\n  alt=\"The producers list in the sticky menu\"\n  loading=\"lazy\"\n  decoding=\"async\"\n  class=\"full-width\"\n/\u003e\n\n\nThe producers list in the sticky menu\u003c/p\u003e\n\u003ch3 id=\"displaying-the-current-farm\"\u003eDisplaying the current farm\u003c/h3\u003e\n\u003cp\u003eTo do that, we added a “scrollY” attribute to our list components:\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/fpetitit/bd6c592cd76cd7417be8e35078f34a55\"\u003e\u003c/script\u003e\n\u003cp\u003eIt allowed us to determine the current producer by looking for the first element of the list having a scrollY visible according to \u003ccode\u003ewindow.pageYOffset\u003c/code\u003e:\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/fpetitit/c9e3de2a22182e9a9995eb94c70847c0.js\"\u003e\u003c/script\u003e\n\u003ch3 id=\"going-to-a-specific-producer\"\u003eGoing to a specific producer\u003c/h3\u003e\n\u003cp\u003eFinally, going to a specific producer was done by calculating the position of the producer card by accumulating the heights of the previous components from the list and scrolling to the position:\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/fpetitit/60995479f18922d6caf54dcd602376d2.js\"\u003e\u003c/script\u003e\n\u003ch3 id=\"conclusion--the-pros-and-cons-of-react-virtualized\"\u003eConclusion : the pros and cons of React Virtualized\u003c/h3\u003e\n\u003cp\u003eWe are quite happy of our new sale page and React Virtualized was really a great tool to help use prototyping and developing all the features that we wanted.\u003c/p\u003e\n\u003cp\u003eThe performance are very good, it works well on all the browsers that we support, especially on the most difficult to support for us which are IE 11 and Safari Mobile on relatively old iOS devices.\u003c/p\u003e\n\u003cp\u003eWe were concerned by 2 problems until now. Both are due to the fact that the whole list is never present into the DOM:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003esearching into the list by the find function of the browsers (“ctrl + f”) is working only in the visible rows, but we provide a Search functionality in the sale page that the user should use instead of the browser’s function, and that provides more intelligent results\u003c/li\u003e\n\u003cli\u003esome CSS rules cannot be used, for example selectors like \u003ca href=\"https://developer.mozilla.org/en-US/docs/Web/CSS/:first-of-type\"\u003efirst-of-type\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIf you have faced challenges of the same type, please share your experiences in the comments of this blog post :)\u003c/p\u003e\n",
      "url": "https://francoispetitit.com/posts/how-we-used-react-virtualized-to-boost-our-sale-page/",
      "date_published": "18076-18-09T752:1818:00+02:00",
      "date_modified": "18076-18-09T752:1818:00+02:00",
      "author": {
        "name": "François Petitit",
        "url": "https://francoispetitit.com/"
      }
    },
    
    {
      "id": "b365f886c6540df51d5423c319a4b664794095c0",
      "title": "Paris Web Openid Connect France Connect",
      "summary": "",
      "content_text": "Présentation à Paris Web - OpenID Connect : mise en oeuvre sur France Connect J\u0026rsquo;ai eu la chance et l\u0026rsquo;opportunité de présenter un retour d\u0026rsquo;expérience à Paris Web : il s\u0026rsquo;agit de l\u0026rsquo;utilisation du protocole OpenID Connect sur le projet France Connect, lorsque j\u0026rsquo;étais le Technical Leader de l\u0026rsquo;équipe.\nLa vidéo est disponibile ici :\nOpenID Connect, le nouveau standard d\u0026#039;authentification sur le web : mise en oeuvre sur FranceConnect from Paris Web on Vimeo.\nLe sujet FranceConnect est un nouvel outil visant à améliorer l\u0026rsquo;accès aux administrations françaises en facilitant l\u0026rsquo;authentification et l\u0026rsquo;identification des usagers. Pour cela, nous avons mis en oeuvre le protocole OpenID Connect.\nCe protocole ouvert basé sur OAuth2, successeur de OpenID, et soutenu par des grands acteurs, permet à une application cliente d\u0026rsquo;utiliser n\u0026rsquo;importe quel fournisseur d\u0026rsquo;identité pourvu qu\u0026rsquo;il implémente aussi ce standard.\nNous verrons dans cette présentation quels sont les cas d\u0026rsquo;usages de ce protocole (authentification sur le web, sur des applications mobiles…), quels sont ses avantages et inconvénients, et comment le mettre en oeuvre avec Node.js.\n",
      "content_html": "\u003ch1 id=\"présentation-à-paris-web---openid-connect--mise-en-oeuvre-sur-france-connect\"\u003ePrésentation à Paris Web - OpenID Connect : mise en oeuvre sur France Connect\u003c/h1\u003e\n\u003cp\u003eJ\u0026rsquo;ai eu la chance et l\u0026rsquo;opportunité de présenter un retour d\u0026rsquo;expérience à Paris Web : il s\u0026rsquo;agit de l\u0026rsquo;utilisation du protocole OpenID Connect sur le projet France Connect, lorsque j\u0026rsquo;étais le Technical Leader de l\u0026rsquo;équipe.\u003c/p\u003e\n\u003cp\u003eLa vidéo est disponibile ici :\u003c/p\u003e\n\u003ciframe src=\"https://player.vimeo.com/video/143169752?h=e8a06887a2\" width=\"640\" height=\"360\" frameborder=\"0\" allow=\"autoplay; fullscreen; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\u003cp\u003e\u003ca href=\"https://vimeo.com/143169752\"\u003eOpenID Connect, le nouveau standard d\u0026#039;authentification sur le web : mise en oeuvre sur FranceConnect\u003c/a\u003e from \u003ca href=\"https://vimeo.com/parisweb\"\u003eParis Web\u003c/a\u003e on \u003ca href=\"https://vimeo.com\"\u003eVimeo\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id=\"le-sujet\"\u003eLe sujet\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://franceconnect.gouv.fr/\"\u003eFranceConnect\u003c/a\u003e est un nouvel outil visant à améliorer l\u0026rsquo;accès aux administrations françaises en facilitant l\u0026rsquo;authentification et l\u0026rsquo;identification des usagers. Pour cela, nous avons mis en oeuvre le protocole \u003ca href=\"https://openid.net/developers/how-connect-works/\"\u003eOpenID Connect\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eCe protocole ouvert basé sur OAuth2, successeur de OpenID, et soutenu par des grands acteurs, permet à une application cliente d\u0026rsquo;utiliser n\u0026rsquo;importe quel fournisseur d\u0026rsquo;identité pourvu qu\u0026rsquo;il implémente aussi ce standard.\u003c/p\u003e\n\u003cp\u003eNous verrons dans cette présentation quels sont les cas d\u0026rsquo;usages de ce protocole (authentification sur le web, sur des applications mobiles…), quels sont ses avantages et inconvénients, et comment le mettre en oeuvre avec Node.js.\u003c/p\u003e\n",
      "url": "https://francoispetitit.com/posts/paris-web-openid-connect-france-connect/",
      "date_published": "10106-10-09T101:1010:00+02:00",
      "date_modified": "10106-10-09T101:1010:00+02:00",
      "author": {
        "name": "François Petitit",
        "url": "https://francoispetitit.com/"
      }
    },
    
    {
      "id": "535b350f4af0a36d118a0a7037e5fc40810922b6",
      "title": "Les Nouvelles Architectures Web Et Leur Impact Sur Les Dsi Partie 2",
      "summary": "",
      "content_text": "cet article a été publié une première fois le 29/10/2013 sur le blog d\u0026rsquo;OCTO Technology : https://blog.octo.com/les-nouvelles-architectures-front-web-et-leur-impact-sur-la-dsi-partie-2\nDans la partie 1 de cet article, nous avons traité des nouvelles architectures front-end basées sur des applications Web massivement Javascript appelant des API offertes par un serveur back-end : les nouvelles architectures front Web et leur impact sur les DSI - Partie 1.\nNous avons vu qu\u0026rsquo;elles sont apparues ces dernières années grâce à l\u0026rsquo;augmentation des performances des navigateurs et à l\u0026rsquo;amélioration des outils d\u0026rsquo;industrialisation des développements Javascript.\nDans cette seconde partie, nous nous intéresserons aux raisons pour lesquelles on devrait choisir ces nouvelles architectures, aux opportunités qu\u0026rsquo;elles offrent, et aux conséquences sur les organisations des directions informatiques.\nPourquoi utiliser ces nouvelles archis? Pour mutualiser le code back-end pour de multiples clients Un atout majeur de cette architecture est la mise en place d\u0026rsquo;une API : orientée fonctionnel et développée dans une technologie standard comme JSON sur HTTP, celle-ci pourra être utilisée par de nombreux autres clients que l\u0026rsquo;application Web initiale. De plus, c\u0026rsquo;est un pattern d\u0026rsquo;architecture déjà connu car c\u0026rsquo;est en général celui utilisé par les applications mobiles : on a donc déjà une certaine expérience dans les DSI pour mettre en place une brique de Web services faisant une façade devant la complexité du SI et utilisable par les applications mobiles. Cependant avec une architecture Web MVC server-side, on aurait dû développer tout d\u0026rsquo;abord le service côté serveur qui appelle le back-office métier, puis l\u0026rsquo;expose à l\u0026rsquo;application Web. Avec une architecture MV* côté client, on n\u0026rsquo;a plus besoin de cette couche et consommer directement les services de l\u0026rsquo;API si elle existe déjà. De même, si on part de zéro, on peut investir dès le début sur une API \u0026ldquo;propre\u0026rdquo; débarrassée de toute spécificité liée à la technologie utilisée pour les IHM.\n\u0026hellip; et ouvrir une API vers l\u0026rsquo;extérieur ? Si vous détenez une API pour vos applications, la rendre accessible à l\u0026rsquo;extérieur sera d\u0026rsquo;autant plus facilitée. Je vous invite à relire cet article sur notre blog : les Patterns des Grands du Web : « OpenAPI » ou écosystème ouvert. Cela nécessite bien évidemment d\u0026rsquo;autres éléments, notamment une démarche particulière et la mise en place d\u0026rsquo;un écosystème pour les clients de l\u0026rsquo;API, mais avoir déjà développé les services est une opportunité à bien considérer !\nPour améliorer la productivité des développements Avec le recul que nous avons chez OCTO, où l\u0026rsquo;on a déjà réalisé sur cette architecture et mis en production plus d\u0026rsquo;une dizaine de projets de tous types, Web mobile ou desktop, applications métier ou de Dataviz, utiliser des technologies comme AngularJS et BackboneJS améliore sensiblement la productivité, par-rapport à utiliser des frameworks MVC server-side comme JSF ou GWT par exemple dans le monde Java. Cela est tout de même plus nuancé si l\u0026rsquo;on compare avec des outils de développements plus proche du Web comme Rails ou PHP, où les archis MV* côté client conservent tout de même l\u0026rsquo;avantage de la consommation d\u0026rsquo;API agnostiques comme vu précédemment. Mais si on a des serveurs sur Java ou .Net par exemple, et qu\u0026rsquo;on ne veut pas introduire un nouveau middleware dans son infra, alors la productivité des développements front-end avec des technologies comme AngularJS sera un très fort atout.\nPour produire des applications Web plus puissantes, plus riches, plus ergonomiques Au-delà de la productivité, il faut aussi comparer le produit final. Or quand on développe avec un framework MV*, on développe toute l\u0026rsquo;application dans et pour le navigateur. Cela permet au développeur d\u0026rsquo;accéder directement et facilement à tous les services offerts par celui-ci, et depuis l\u0026rsquo;avènement de HTML5 ils sont nombreux : stockage de données, offline, accès au système de fichier, multi-threading, push de données\u0026hellip; Nous n\u0026rsquo;exploitons aujourd\u0026rsquo;hui même pas 10% des capacités de nos navigateurs, et cela non pas par manque de cas d\u0026rsquo;usages mais par manque de facilités pour le développement JavaScript dans le navigateur. Or justement avec ces nouvelles technologies, on gagne la possibilité d\u0026rsquo;expérimenter souvent et rapidement car l\u0026rsquo;environnement de développement est extrêmement rapide (notamment le live-reload qui permet de recharger du code dans le navigateur à peine après avoir enregistré un fichier source et à l\u0026rsquo;utilisation de NodeJs en serveur de développement, beaucoup plus rapide que les serveurs Java ou .Net). On se ré-approprie véritablement le navigateur, qui n\u0026rsquo;est plus la boîte noire qui vous veut du mal comme quand il fallait sans cesse débugger du code sur les navigateurs standards du marchés. Il est la nouvelle plateforme, qui vous ouvre des nouveaux horizons de créativité.\nCombien en utilisez-vous aujourd\u0026rsquo;hui? Combien en exploiterez-vous dans 1 an?\nPour remplacer une application lourde complexe et la déployer en SAAS Les éditeurs sont sont de plus en plus nombreux à porter leurs solutions client lourd vers des technologies Web. On pourra évoquer Google Apps qui fournit un webmail bien connu et une suite office depuis longtemps. Mais on est encore plus frappé par la dernière mouture de Microsoft Office, Office 365, qui est intégralement sur le cloud, et de modèle de vente par licence à des abonnements en mode SAAS. Cela est rendu possible par l\u0026rsquo;exploitation des nouvelles capacités des navigateurs, et utiliser des architectures MV* massivement Javascript et bien outillées est clairement la solution aujourd\u0026rsquo;hui pour adresser ces besoins.\nEnfin, un domaine jusqu\u0026rsquo;ici souvent réservé aux applications lourdes est celui des applications métiers complexes. Cela s\u0026rsquo;expliquait principalement par un manque de performances des technos Web. Les DSI souhaitent généralement se désendetter de technologies de clients lourds comme VB ou Swing, mais peu de nouvelles solutions pérennes et ouvertes ont émergé. Un des derniers challenger était Flex, mais son destin est entre les mains d\u0026rsquo;Adobe et ne semble guère rassurant. Un autre est .Net avec WPF, lié à l\u0026rsquo;écosystème Microsoft. GWT avait tenté et réussi à rendre le développement d\u0026rsquo;applications Web relativement complexes un choix réaliste. Mais de même Google, toujours pionnier en matière technologique, a décidé de réduire ses investissements sur cette plateforme, et d\u0026rsquo;embaucher les développeurs du framework AngularJS et de développer la plateforme Dart. L\u0026rsquo;alternative à la conservation des anciennes applications est aujourd\u0026rsquo;hui à chercher dans les nouvelles architectures Web. On restera tout de même encore mesurés devant un relatif manque de maturité des technologies avant de déclencher des refontes d\u0026rsquo;applications complexes, non pas que les plateformes elles-mêmes (le Web et les navigateurs) ne soient assez matures, mais que les technologies de développements évoluent très vite et peuvent induire un coût de maintenance non négligeable pour une DSI qui n\u0026rsquo;est pas \u0026ldquo;pure player\u0026rdquo; du Web.\nQuels impacts sur ma DSI? Les impacts de ces technologies sur la DSI du point de vue technique sont finalement assez faibles : on savait déjà développer et faire tourner des applications Web en production. De même, la mise en place d\u0026rsquo;une API implique peu de nouveautés et les patterns pour les sécuriser sont déjà connus car utilisés dans les applications mobiles et les RIA.\nLa nouveauté est plus à chercher dans les compétences requises pour le développement, et notamment en JavaScript.\nLe besoin de nouvelles compétences JavaScript Il faut revenir à 5 ou 10 ans en arrière pour comprendre l\u0026rsquo;aversion des DSI au développement en JavaScript. A l\u0026rsquo;époque, ce langage était très difficilement maintenable car il offre nativement peu de garde-fous : par de typage, pas de compilation, pas de modèle objet\u0026hellip; JavaScript était vu comme un langage de bidouilleurs à bannir en production et dont le seul mérite était d\u0026rsquo;être utilisé par tous les navigateurs. A l\u0026rsquo;aune du Web 2.0, pour faire des applications Web plus riches, on a donc créé des frameworks de développements pour générer du JavaScript sans en écrire : JSF, GWT, ASP.Net, etc. Les limites engendrées par ces librairies (difficultés à introduire du comportement non standard, complexité de debuggage, dépendances fortes avec les éditeurs de librairies) ainsi que l\u0026rsquo;illusion de pouvoir confier à des développeurs purement \u0026ldquo;backs\u0026rdquo; Java ou .Net ont conduits à des désillusions tant sur les applications produites que sur la productivité.\nAvec les nouveaux frameworks MV*, on retrouve une liberté dans les développements et une meilleure productivité, à condition d\u0026rsquo;accepter de développer directement en JavaScript. Le prix à payer est donc l\u0026rsquo;acquisition de compétences en JavaScript, et même de nouvelles compétences : typiquement, il ne s\u0026rsquo;agit plus de savoir intégrer un plug-in jQuery pour apporter un peu de dynamisme à une page web statique, mais de développer une application entière avec du JavaScript et un framework approprié.\nDes connaissances en architecture applicative et en industrialisation des développements (tests, etc.) sont un pré-requis pour ces nouvelles technologies. Heureusement, la facilité d\u0026rsquo;utilisation des derniers frameworks MV* et les cadres structurants qu\u0026rsquo;ils offrent permettent de réduire très largement le ticket d\u0026rsquo;entrée pour un développeur encore non expert.\nEt c\u0026rsquo;est bien là le fait majeur de cette évolution : la prise en main du développement d\u0026rsquo;applications MV côté client est désormais aussi aisée que celle d\u0026rsquo;applications MVC classiques.*\nLa tentation de créer des équipes par technos front-end et back-end Le découplage technologique grandissant entre technologies front Web HTML/CSS/JavaScript et back (sauf à utiliser NodeJS sur le serveur!) engendrent une plus grande distinction entre les développeurs suivant la couche technique sur laquelle ils travaillent. C\u0026rsquo;est une opportunité d\u0026rsquo;améliorer l\u0026rsquo;expertise sur une technologie et la complexification fonctionnelle des applications le nécessite souvent, mais c\u0026rsquo;est aussi un risque de perdre une certaine polyvalence.\nUn autre impact concerne l\u0026rsquo;organisation des équipes : on pourra plus facilement dédier des équipes au développement front et d\u0026rsquo;autres au développement back. Mais cette idée a déjà été abordé dans cet article, où l\u0026rsquo;on constate qu\u0026rsquo;elle n\u0026rsquo;est pas forcément le meilleur choix : https://blog.octo.com/feature-team/. En synthèse si vous n\u0026rsquo;avez pas le temps de le relire, le mode d\u0026rsquo;organisation le plus efficace est plutôt de grouper les équipes en \u0026ldquo;feature teams\u0026rdquo; dédiées à des fonctionnalité et couvrant l\u0026rsquo;ensemble des compétences nécessaires pour les mettre en place.\nConclusion : quelques écueils à éviter En conclusion, on gardera à l\u0026rsquo;esprit que les nouvelles architecture Web apportent de grandes opportunités pour le développement d\u0026rsquo;applications et les usages pouvant être faits par les utilisateurs finaux et les DSI.\nOn évoquera tout de même quelques axes de réflexions à ne pas écarter lors d\u0026rsquo;un choix de technologies : - ces solutions ne sont pas forcément les meilleurs pour tous les cas d\u0026rsquo;usages : par exemple pour un site statique, on peut trouver des solutions plus performantes par-rapport aux performances et au référencement - la comparaison avec des applications natives, véritable point de tension dans les choix pour adresser les usages en mobilité, n\u0026rsquo;est pas encore à l\u0026rsquo;avantage du Web : il reste toujours de nombreuses choses possibles en natif impossibles en Web. A chaque contexte correspondra une stratégie de choix différente.\nPour aller plus loin une présentation de Julien Jakubowski à Devoxx sur l\u0026rsquo;industrialisation avec JavaScript : http://parleys.com/play/517bf74ee4b0736a5fa66a38/chapter0/about sur la problématique de référencement de single page application : https://blog.octo.com/seo-spa-angular/\n",
      "content_html": "\u003cp\u003e\u003cem\u003ecet article a été publié une première fois le 29/10/2013 sur le blog d\u0026rsquo;OCTO Technology : \u003ca href=\"https://blog.octo.com/les-nouvelles-architectures-front-web-et-leur-impact-sur-la-dsi-partie-2\"\u003ehttps://blog.octo.com/les-nouvelles-architectures-front-web-et-leur-impact-sur-la-dsi-partie-2\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eDans la \u003ca href=\"https://www.francoispetitit.com/posts/les-nouvelles-architectures-web-et-leur-impact-sur-les-dsi-partie-1/\"\u003epartie 1 de cet article\u003c/a\u003e, nous avons traité des nouvelles architectures front-end basées sur des applications Web massivement Javascript appelant des API offertes par un serveur back-end : les nouvelles architectures front Web et leur impact sur les DSI - Partie 1.\u003c/p\u003e\n\u003cp\u003eNous avons vu qu\u0026rsquo;elles sont apparues ces dernières années grâce à l\u0026rsquo;augmentation des performances des navigateurs et à l\u0026rsquo;amélioration des outils d\u0026rsquo;industrialisation des développements Javascript.\u003c/p\u003e\n\u003cp\u003eDans cette seconde partie, nous nous intéresserons aux raisons pour lesquelles on devrait choisir ces nouvelles architectures, aux opportunités qu\u0026rsquo;elles offrent, et aux conséquences sur les organisations des directions informatiques.\u003c/p\u003e\n\u003ch2 id=\"pourquoi-utiliser-ces-nouvelles-archis\"\u003ePourquoi utiliser ces nouvelles archis?\u003c/h2\u003e\n\u003ch3 id=\"pour-mutualiser-le-code-back-end-pour-de-multiples-clients\"\u003ePour mutualiser le code back-end pour de multiples clients\u003c/h3\u003e\n\u003cp\u003e\u003cimg\n  src=\"image.png\"\n  alt=\"schema API front back\"\n  loading=\"lazy\"\n  decoding=\"async\"\n  class=\"full-width\"\n/\u003e\n\n\u003c/p\u003e\n\u003cp\u003eUn atout majeur de cette architecture est la mise en place d\u0026rsquo;une API : orientée fonctionnel et développée dans une technologie standard comme JSON sur HTTP, celle-ci pourra être utilisée par de nombreux autres clients que l\u0026rsquo;application Web initiale. De plus, c\u0026rsquo;est un pattern d\u0026rsquo;architecture déjà connu car c\u0026rsquo;est en général celui utilisé par les applications mobiles : on a donc déjà une certaine expérience dans les DSI pour mettre en place une brique de Web services faisant une façade devant la complexité du SI et utilisable par les applications mobiles. Cependant avec une architecture Web MVC server-side, on aurait dû développer tout d\u0026rsquo;abord le service côté serveur qui appelle le back-office métier, puis l\u0026rsquo;expose à l\u0026rsquo;application Web. Avec une architecture MV* côté client, on n\u0026rsquo;a plus besoin de cette couche et consommer directement les services de l\u0026rsquo;API si elle existe déjà. De même, si on part de zéro, on peut investir dès le début sur une API \u0026ldquo;propre\u0026rdquo; débarrassée de toute spécificité liée à la technologie utilisée pour les IHM.\u003c/p\u003e\n\u003ch3 id=\"-et-ouvrir-une-api-vers-lextérieur-\"\u003e\u0026hellip; et ouvrir une API vers l\u0026rsquo;extérieur ?\u003c/h3\u003e\n\u003cp\u003eSi vous détenez une API pour vos applications, la rendre accessible à l\u0026rsquo;extérieur sera d\u0026rsquo;autant plus facilitée. Je vous invite à relire cet article sur notre blog : les Patterns des Grands du Web : « OpenAPI » ou écosystème ouvert. Cela nécessite bien évidemment d\u0026rsquo;autres éléments, notamment une démarche particulière et la mise en place d\u0026rsquo;un écosystème pour les clients de l\u0026rsquo;API, mais avoir déjà développé les services est une opportunité à bien considérer !\u003c/p\u003e\n\u003ch2 id=\"pour-améliorer-la-productivité-des-développements\"\u003ePour améliorer la productivité des développements\u003c/h2\u003e\n\u003cp\u003eAvec le recul que nous avons chez OCTO, où l\u0026rsquo;on a déjà réalisé sur cette architecture et mis en production plus d\u0026rsquo;une dizaine de projets de tous types, Web mobile ou desktop, applications métier ou de Dataviz, utiliser des technologies comme AngularJS et BackboneJS améliore sensiblement la productivité, par-rapport à utiliser des frameworks MVC server-side comme JSF ou GWT par exemple dans le monde Java. Cela est tout de même plus nuancé si l\u0026rsquo;on compare avec des outils de développements plus proche du Web comme Rails ou PHP, où les archis MV* côté client conservent tout de même l\u0026rsquo;avantage de la consommation d\u0026rsquo;API agnostiques comme vu précédemment. Mais si on a des serveurs sur Java ou .Net par exemple, et qu\u0026rsquo;on ne veut pas introduire un nouveau middleware dans son infra, alors la productivité des développements front-end avec des technologies comme AngularJS sera un très fort atout.\u003c/p\u003e\n\u003ch2 id=\"pour-produire-des-applications-web-plus-puissantes-plus-riches-plus-ergonomiques\"\u003ePour produire des applications Web plus puissantes, plus riches, plus ergonomiques\u003c/h2\u003e\n\u003cp\u003eAu-delà de la productivité, il faut aussi comparer le produit final. Or quand on développe avec un framework MV*, on développe toute l\u0026rsquo;application dans et pour le navigateur. Cela permet au développeur d\u0026rsquo;accéder directement et facilement à tous les services offerts par celui-ci, et depuis l\u0026rsquo;avènement de HTML5 ils sont nombreux : stockage de données, offline, accès au système de fichier, multi-threading, push de données\u0026hellip; Nous n\u0026rsquo;exploitons aujourd\u0026rsquo;hui même pas 10% des capacités de nos navigateurs, et cela non pas par manque de cas d\u0026rsquo;usages mais par manque de facilités pour le développement JavaScript dans le navigateur. Or justement avec ces nouvelles technologies, on gagne la possibilité d\u0026rsquo;expérimenter souvent et rapidement car l\u0026rsquo;environnement de développement est extrêmement rapide (notamment le \u003cstrong\u003elive-reload\u003c/strong\u003e qui permet de recharger du code dans le navigateur à peine après avoir enregistré un fichier source et à l\u0026rsquo;utilisation de NodeJs en serveur de développement, beaucoup plus rapide que les serveurs Java ou .Net). On se ré-approprie véritablement le navigateur, qui n\u0026rsquo;est plus la boîte noire qui vous veut du mal comme quand il fallait sans cesse débugger du code sur les navigateurs standards du marchés. Il est la nouvelle plateforme, qui vous ouvre des nouveaux horizons de créativité.\u003c/p\u003e\n\u003cp\u003e\u003cimg\n  src=\"image-1.png\"\n  alt=\"HTML5 offre de nombreuses nouvelles fonctionnalités\"\n  loading=\"lazy\"\n  decoding=\"async\"\n  class=\"full-width\"\n/\u003e\n\n\u003c/p\u003e\n\u003cp\u003eCombien en utilisez-vous aujourd\u0026rsquo;hui? Combien en exploiterez-vous dans 1 an?\u003c/p\u003e\n\u003ch2 id=\"pour-remplacer-une-application-lourde-complexe-et-la-déployer-en-saas\"\u003ePour remplacer une application lourde complexe et la déployer en SAAS\u003c/h2\u003e\n\u003cp\u003eLes éditeurs sont sont de plus en plus nombreux à porter leurs solutions client lourd vers des technologies Web. On pourra évoquer Google Apps qui fournit un webmail bien connu et une suite office depuis longtemps. Mais on est encore plus frappé par la dernière mouture de Microsoft Office, Office 365, qui est intégralement sur le cloud, et de modèle de vente par licence à des abonnements en mode SAAS. Cela est rendu possible par l\u0026rsquo;exploitation des nouvelles capacités des navigateurs, et utiliser des architectures MV* massivement Javascript et bien outillées est clairement la solution aujourd\u0026rsquo;hui pour adresser ces besoins.\u003c/p\u003e\n\u003cp\u003eEnfin, un domaine jusqu\u0026rsquo;ici souvent réservé aux applications lourdes est celui des applications métiers complexes. Cela s\u0026rsquo;expliquait principalement par un manque de performances des technos Web. Les DSI souhaitent généralement se désendetter de technologies de clients lourds comme VB ou Swing, mais peu de nouvelles solutions pérennes et ouvertes ont émergé. Un des derniers challenger était Flex, mais son destin est entre les mains d\u0026rsquo;Adobe et ne semble guère rassurant. Un autre est .Net avec WPF, lié à l\u0026rsquo;écosystème Microsoft. GWT avait tenté et réussi à rendre le développement d\u0026rsquo;applications Web relativement complexes un choix réaliste. Mais de même Google, toujours pionnier en matière technologique, a décidé de réduire ses investissements sur cette plateforme, et d\u0026rsquo;embaucher les développeurs du framework AngularJS et de développer la plateforme Dart. L\u0026rsquo;alternative à la conservation des anciennes applications est aujourd\u0026rsquo;hui à chercher dans les nouvelles architectures Web. On restera tout de même encore mesurés devant un relatif manque de maturité des technologies avant de déclencher des refontes d\u0026rsquo;applications complexes, non pas que les plateformes elles-mêmes (le Web et les navigateurs) ne soient assez matures, mais que les technologies de développements évoluent très vite et peuvent induire un coût de maintenance non négligeable pour une DSI qui n\u0026rsquo;est pas \u0026ldquo;pure player\u0026rdquo; du Web.\u003c/p\u003e\n\u003ch2 id=\"quels-impacts-sur-ma-dsi\"\u003eQuels impacts sur ma DSI?\u003c/h2\u003e\n\u003cp\u003eLes impacts de ces technologies sur la DSI du point de vue technique sont finalement assez faibles : on savait déjà développer et faire tourner des applications Web en production. De même, la mise en place d\u0026rsquo;une API implique peu de nouveautés et les patterns pour les sécuriser sont déjà connus car utilisés dans les applications mobiles et les RIA.\u003c/p\u003e\n\u003cp\u003eLa nouveauté est plus à chercher dans les compétences requises pour le développement, et notamment en JavaScript.\u003c/p\u003e\n\u003ch2 id=\"le-besoin-de-nouvelles-compétences-javascript\"\u003eLe besoin de nouvelles compétences JavaScript\u003c/h2\u003e\n\u003cp\u003eIl faut revenir à 5 ou 10 ans en arrière pour comprendre l\u0026rsquo;aversion des DSI au développement en JavaScript. A l\u0026rsquo;époque, ce langage était très difficilement maintenable car il offre nativement peu de garde-fous : par de typage, pas de compilation, pas de modèle objet\u0026hellip; JavaScript était vu comme un langage de bidouilleurs à bannir en production et dont le seul mérite était d\u0026rsquo;être utilisé par tous les navigateurs. A l\u0026rsquo;aune du Web 2.0, pour faire des applications Web plus riches, on a donc créé des frameworks de développements pour générer du JavaScript sans en écrire : JSF, GWT, ASP.Net, etc. Les limites engendrées par ces librairies (difficultés à introduire du comportement non standard, complexité de debuggage, dépendances fortes avec les éditeurs de librairies) ainsi que l\u0026rsquo;illusion de pouvoir confier à des développeurs purement \u0026ldquo;backs\u0026rdquo; Java ou .Net ont conduits à des désillusions tant sur les applications produites que sur la productivité.\u003c/p\u003e\n\u003cp\u003eAvec les nouveaux frameworks MV*, on retrouve une liberté dans les développements et une meilleure productivité, à condition d\u0026rsquo;accepter de développer directement en JavaScript. Le prix à payer est donc l\u0026rsquo;acquisition de compétences en JavaScript, et même de nouvelles compétences : typiquement, il ne s\u0026rsquo;agit plus de savoir intégrer un plug-in jQuery pour apporter un peu de dynamisme à une page web statique, mais de développer une application entière avec du JavaScript et un framework approprié.\u003c/p\u003e\n\u003cp\u003eDes connaissances en architecture applicative et en industrialisation des développements (tests, etc.) sont un pré-requis pour ces nouvelles technologies. Heureusement, la facilité d\u0026rsquo;utilisation des derniers frameworks MV* et les cadres structurants qu\u0026rsquo;ils offrent permettent de réduire très largement le ticket d\u0026rsquo;entrée pour un développeur encore non expert.\u003c/p\u003e\n\u003cp\u003eEt c\u0026rsquo;est bien là le fait majeur de cette évolution : \u003cem\u003e\u003cem\u003ela prise en main du développement d\u0026rsquo;applications MV\u003c/em\u003e côté client est désormais aussi aisée que celle d\u0026rsquo;applications MVC classiques.\u003c/em\u003e*\u003c/p\u003e\n\u003ch2 id=\"la-tentation-de-créer-des-équipes-par-technos-front-end-et-back-end\"\u003eLa tentation de créer des équipes par technos front-end et back-end\u003c/h2\u003e\n\u003cp\u003eLe découplage technologique grandissant entre technologies front Web HTML/CSS/JavaScript et back (sauf à utiliser NodeJS sur le serveur!) engendrent une plus grande distinction entre les développeurs suivant la couche technique sur laquelle ils travaillent. C\u0026rsquo;est une opportunité d\u0026rsquo;améliorer l\u0026rsquo;expertise sur une technologie et la complexification fonctionnelle des applications le nécessite souvent, mais c\u0026rsquo;est aussi un risque de perdre une certaine polyvalence.\u003c/p\u003e\n\u003cp\u003eUn autre impact concerne l\u0026rsquo;organisation des équipes : on pourra plus facilement dédier des équipes au développement front et d\u0026rsquo;autres au développement back. Mais cette idée a déjà été abordé dans cet article, où l\u0026rsquo;on constate qu\u0026rsquo;elle n\u0026rsquo;est pas forcément le meilleur choix : \u003ca href=\"https://blog.octo.com/feature-team/\"\u003ehttps://blog.octo.com/feature-team/\u003c/a\u003e. En synthèse si vous n\u0026rsquo;avez pas le temps de le relire, le mode d\u0026rsquo;organisation le plus efficace est plutôt de grouper les équipes en \u0026ldquo;feature teams\u0026rdquo; dédiées à des fonctionnalité et couvrant l\u0026rsquo;ensemble des compétences nécessaires pour les mettre en place.\u003c/p\u003e\n\u003ch2 id=\"conclusion--quelques-écueils-à-éviter\"\u003eConclusion : quelques écueils à éviter\u003c/h2\u003e\n\u003cp\u003eEn conclusion, on gardera à l\u0026rsquo;esprit que les nouvelles architecture Web apportent de grandes opportunités pour le développement d\u0026rsquo;applications et les usages pouvant être faits par les utilisateurs finaux et les DSI.\u003c/p\u003e\n\u003cp\u003eOn évoquera tout de même quelques axes de réflexions à ne pas écarter lors d\u0026rsquo;un choix de technologies : - ces solutions ne sont pas forcément les meilleurs pour tous les cas d\u0026rsquo;usages : par exemple pour un site statique, on peut trouver des solutions plus performantes par-rapport aux performances et au référencement - la comparaison avec des applications natives, véritable point de tension dans les choix pour adresser les usages en mobilité, n\u0026rsquo;est pas encore à l\u0026rsquo;avantage du Web : il reste toujours de nombreuses choses possibles en natif impossibles en Web. A chaque contexte correspondra une stratégie de choix différente.\u003c/p\u003e\n\u003ch2 id=\"pour-aller-plus-loin\"\u003ePour aller plus loin\u003c/h2\u003e\n\u003cp\u003eune présentation de Julien Jakubowski à Devoxx sur l\u0026rsquo;industrialisation avec JavaScript : \u003ca href=\"http://parleys.com/play/517bf74ee4b0736a5fa66a38/chapter0/about\"\u003ehttp://parleys.com/play/517bf74ee4b0736a5fa66a38/chapter0/about\u003c/a\u003e\nsur la problématique de référencement de single page application : \u003ca href=\"https://blog.octo.com/seo-spa-angular/\"\u003ehttps://blog.octo.com/seo-spa-angular/\u003c/a\u003e\u003c/p\u003e\n",
      "url": "https://francoispetitit.com/posts/les-nouvelles-architectures-web-et-leur-impact-sur-les-dsi-partie-2/",
      "date_published": "30106-30-09T1011:3030:00+02:00",
      "date_modified": "30106-30-09T1011:3030:00+02:00",
      "author": {
        "name": "François Petitit",
        "url": "https://francoispetitit.com/"
      }
    },
    
    {
      "id": "81989193ee8e8bb68b3497d7ca18ac1cbb11018d",
      "title": "Les Nouvelles Architectures Web Et Leur Impact Sur Les Dsi Partie 1",
      "summary": "",
      "content_text": "cet article a été publié une première fois le 29/10/2013 sur le blog d\u0026rsquo;OCTO Technology : https://blog.octo.com/les-nouvelles-architectures-front-web-et-leur-impact-sur-les-dsi-partie-1\nLes applications Web évoluent. Depuis les premiers sites en HTML statique jusqu\u0026rsquo;aux applications AJAX de ces dernières années, en passant par les multiples technologies de sites Web dynamiques (PHP, ASP, Java, Rails\u0026hellip;), les architectures applicatives et les outils pour les mettre en place connaissent régulièrement des avancées majeures et des points de ruptures.\nDepuis deux ans, nous voyons venir une nouvelle vague technologique qui submerge le paysage des applications Web. Celle-ci n\u0026rsquo;a pas encore de nom bien défini comme ont pu l\u0026rsquo;avoir les RIA ou AJAX. Nous les appellerons les \u0026ldquo;architectures MV* côté client\u0026rdquo;.\nElles se constituent principalement de ce principe d\u0026rsquo;architecture : le serveur ne doit plus gérer l\u0026rsquo;affichage mais seulement envoyer des données brutes à afficher, et toute la génération des écrans et la gestion des interactions avec l\u0026rsquo;utilisateur doivent être géré côté client, c\u0026rsquo;est-à-dire dans le navigateur.\nDans ce billet, nous préciserons cette architecture et expliquer les raisons de son émergence. Dans un second billet, nous verrons pourquoi il est pertinent de les mettre en place dès aujourd\u0026rsquo;hui, les opportunités qu\u0026rsquo;elles offrent, et quels sont les impacts à prévoir pour les DSI.\nLes nouvelles archis front Web : de quoi parle-t-on ? Le schéma ci-dessous illustre l\u0026rsquo;évolution des architectures d\u0026rsquo;applications Web :\nModèle 1 : application Web classique Dans le premier schema, l\u0026rsquo;application Web est principalement exécutée côté serveur. Celui-ci envoie donc directement au navigateur les pages HTML, le CSS et éventuellement du JavaScript pour faire quelques comportement riches. Ensuite, à chaque action utilisateur nécessitant de nouvelles données, le serveur est interrogé et renvoie la nouvelle page HTML.\nModèle 2 : application Web AJAX Le deuxième schema introduit le pattern AJAX, pour Asynchronous Javascript And XML. apparu au milieu des années 2000 (voir l\u0026rsquo;article de Jesse James Garrett : http://www.adaptivepath.com/ideas/ajax-new-approach-web-applications/ ).\nCe principe d\u0026rsquo;architecture permet de rendre l\u0026rsquo;application plus réactive en réduisant les échanges entre le navigateur et le serveur : lorsqu\u0026rsquo;une action utilisateur engendre un appel client pour récupérer des nouvelles données, on ne va rafraîchir qu\u0026rsquo;une portion de l\u0026rsquo;écran et non plus toute la page. Le serveur va alors renvoyer seulement des fragments d\u0026rsquo;IHM. Cela nécessitait la mise en place d\u0026rsquo;outils JavaScript côté client pour gérer ces rafraîchissements partiels, que ce soit par exemple en utilisant la librairie jQuery et sa fonction $.ajax, ou en utilisant des outils plus intégrés aux plateformes serveurs comme Java Server Faces ou Google Web Toolkit pour Java.\nCette architecture apportait plus de réactivité mais aussi plus de complexité. Les outils pour la mettre en place engendraient de nombreux écueils : l\u0026rsquo;utilisation massive de jQuery rendait une application impossible à maintenir sans mettre en place des règles d\u0026rsquo;architectures techniques précises et nécessitant de très fortes compétences (ce qu\u0026rsquo;offrent aujourd\u0026rsquo;hui les frameworks MV* comme Backbone JS ou AngularJS), et les frameworks côté serveur comme JSF pour Java étaient trop lourds et trop complexes malgré leur volonté apparente de simplifier les développements, induisant de nombreux bugs et problèmes de performances.\nModèle 3 : application Web MV* côté client Le troisième schéma représente la nouvelle architecture dont il est question ici : les architectures MV côté client*. Le principe est ici en rupture avec les deux premières : cette fois le serveur ne renvoie que des données brutes non mises en forme pour l\u0026rsquo;affichage. C\u0026rsquo;est côté client, dans le navigateur, que l\u0026rsquo;écran est généré.\nLe terme MV* se réfère au pattern MVC pour [http://fr.wikipedia.org/wiki/Mod%C3%A8le-vue-contr%C3%B4leur](Modèle Vue Contrôleur), qui est très utilisé côté serveur pour découper les différentes problématiques de gestion des vues et des données. Nous utilisons de plus en plus le terme MV* pour les nouvelles architectures afin de montrer que l\u0026rsquo;implémentation dans les applications est souvent, par pragmatisme, un peu différente du MVC pur. Cela reste un débat d\u0026rsquo;expert\u0026hellip;\nL\u0026rsquo;important dans cette nouvelle architecture est donc le déplacement de toute la logique d\u0026rsquo;IHM du serveur vers le client.\nCette séparation des responsabilités entre le serveur et le client qui n\u0026rsquo;est pas une nouveauté en soi a été remise au goût du jour par les applications natives pour mobiles, consommant des API indépendantes des clients consommateurs. Les nouvelles architectures d\u0026rsquo;applications Web étendent ce choix aux applications Web.\nPourquoi ces nouvelles architectures n\u0026rsquo;ont pas été mises en oeuvre plus tôt ? Au fond, le langage JavaScript existe depuis que le Web existe, le principe ne semble pas si révolutionnaire que ça surtout qu\u0026rsquo;il s\u0026rsquo;apparente fortement aux applications client-serveur classiques existant avant le Web, alors pourquoi ne pas avoir pensé à ces architectures plus tôt ?\nLa réponse est simple : ce n\u0026rsquo;était pas possible, sauf à s\u0026rsquo;appeler Google !\nEn effet, 2 facteurs bridaient les possibilités de développement JavaScript :\nles capacités et les performances limitées des navigateurs le manque d\u0026rsquo;industrialisation du développement JavaScript La fin des limitations des navigateurs Le premier point était évident jusqu\u0026rsquo;à l\u0026rsquo;arrivée des dernières version d\u0026rsquo;Internet Explorer 9 et encore plus Internet Explorer 10. Les lenteurs et les nombreux bugs des versions précédentes d\u0026rsquo;Internet Explorer interdisaient de déployer des applications utilisant massivement JavaScript.\nSauf à disposer de la force de frappe d\u0026rsquo;une équipe d\u0026rsquo;ingénieurs Google, vouloir développer un Gmail dans Internet Explorer 6 n\u0026rsquo;était tout simplement pas réaliste.\nCela a bien changé depuis que Firefox et encore plus Chrome ont bousculé le marché et que Microsoft a rattrapé son retard, comme le montre le graphique ci-dessous :\nMontrant les résultats des tests de performances JavaScript Sunspider de différents navigateurs, ce schema illustre parfaitement la rupture qui est arrivée aux alentours de 2010, avec l\u0026rsquo;amélioration des performances d\u0026rsquo;Internet Explorer : les performances entre IE 6 et IE8 à ce test ont été améliorées d\u0026rsquo;un facteur x25 en passant de 177000 ms à 7000 ms !\nDepuis les performances continuent de s\u0026rsquo;améliorer sensiblement, et cela couplé aux nouvelles capacités des terminaux aussi bien mobiles que fixes permet d\u0026rsquo;utiliser le navigateurs pour autre chose que l\u0026rsquo;affichage de pages Web : générer les pages dynamiquement, faire du dessin 2D ou 3D, exécuter des algorithmes complexes, etc.\nL\u0026rsquo;industrialisation du développement JavaScript Avoir une plateforme d\u0026rsquo;exécution puissante ne servirait à rien si on ne pouvait pas développer efficacement pour.\nLa deuxième révolution technologique du développement Web concerne justement l\u0026rsquo;outillage de développement JavaScript.\nSi vous suivez le blog OCTO, vous avez déjà pu voir passer des articles concernant par exemple AngularJS ou Grunt. Ce sont justement deux outils illustrant le nouvel écosystème de développement JavaScript, que l\u0026rsquo;on peut résumer en deux grandes familles d\u0026rsquo;outils :\nles frameworks de développement : là où on utilisait déjà des librairies comme jQuery, qui facilitaient certains développement en JavaScript, les développeurs disposent désormais de véritables frameworks permettant de structurer l\u0026rsquo;application. L\u0026rsquo;intérêt de ces frameworks est double : accélérer les développements et assurer une bonne maintenabilité du code. Parmi les plus connus aujourd\u0026rsquo;hui on trouve notamment AngularJS, BackboneJS et EmberJS.\nles outils d\u0026rsquo;industrialisation : l\u0026rsquo;industrialisation des développements JavaScript a explosé ces deux dernières années, en s\u0026rsquo;inspirant fortement de ce qui a déjà été fait pour les autres plateformes comme Java. De la même manière que les développeurs Java utilisent Maven pour automatiser le build et les tests de leurs applications, les développeurs JavaScript peuvent aujourd\u0026rsquo;hui utiliser Grunt pour automatiser les tests et la construction de leur application, ainsi que le workflow spécifique au développement front : concaténation des fichiers, obfuscation, minification, génération de sprites CSS, etc. L\u0026rsquo;ensemble de ces outils a déjà été abordé dans cet article du blog : https://blog.octo.com/jenkins-pour-le-back-notepad-pour-le-front/ .\nL\u0026rsquo;industrialisation du développement Javascript est par ailleurs poussée également par le fait que l\u0026rsquo;utilisation de Javascript s\u0026rsquo;étend à d\u0026rsquo;autres domaines que les applications Web, et notamment au développement serveur avec NodeJS. Cela d\u0026rsquo;autant plus frappant que NodeJS est utilisé comme socle technique par GruntJS et ses nombreux plug-ins.\nEn conclusion, tous les outils sont là en 2013 pour faire du développement JavaScript de manière efficace et industrielle.\nConclusion de la première partie Dans cet article, nous avons présenté ce que l\u0026rsquo;on entend par \u0026ldquo;architectures MV* côté client\u0026rdquo;, et pourquoi elles émergent aujourd\u0026rsquo;hui.\nDans les parties suivantes, nous verrons pourquoi il faut utiliser ces architectures dès aujourd\u0026rsquo;hui, quels sont les écueils à éviter et quels sont les impacts sur vos DSI.\n",
      "content_html": "\u003cp\u003e\u003cem\u003ecet article a été publié une première fois le 29/10/2013 sur le blog d\u0026rsquo;OCTO Technology : \u003ca href=\"https://blog.octo.com/les-nouvelles-architectures-front-web-et-leur-impact-sur-les-dsi-partie-1\"\u003ehttps://blog.octo.com/les-nouvelles-architectures-front-web-et-leur-impact-sur-les-dsi-partie-1\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eLes applications Web évoluent. Depuis les premiers sites en HTML statique jusqu\u0026rsquo;aux applications AJAX de ces dernières années, en passant par les multiples technologies de sites Web dynamiques (PHP, ASP, Java, Rails\u0026hellip;), les architectures applicatives et les outils pour les mettre en place connaissent régulièrement des avancées majeures et des points de ruptures.\u003c/p\u003e\n\u003cp\u003eDepuis deux ans, nous voyons venir une nouvelle vague technologique qui submerge le paysage des applications Web. Celle-ci n\u0026rsquo;a pas encore de nom bien défini comme ont pu l\u0026rsquo;avoir les RIA ou AJAX. Nous les appellerons les \u0026ldquo;architectures MV* côté client\u0026rdquo;.\u003c/p\u003e\n\u003cp\u003eElles se constituent principalement de ce principe d\u0026rsquo;architecture : le serveur ne doit plus gérer l\u0026rsquo;affichage mais seulement envoyer des données brutes à afficher, et toute la génération des écrans et la gestion des interactions avec l\u0026rsquo;utilisateur doivent être géré côté client, c\u0026rsquo;est-à-dire dans le navigateur.\u003c/p\u003e\n\u003cp\u003eDans ce billet, nous préciserons cette architecture et expliquer les raisons de son émergence. Dans un second billet, nous verrons pourquoi il est pertinent de les mettre en place dès aujourd\u0026rsquo;hui, les opportunités qu\u0026rsquo;elles offrent, et quels sont les impacts à prévoir pour les DSI.\u003c/p\u003e\n\u003ch2 id=\"les-nouvelles-archis-front-web--de-quoi-parle-t-on-\"\u003eLes nouvelles archis front Web : de quoi parle-t-on ?\u003c/h2\u003e\n\u003cp\u003eLe schéma ci-dessous illustre l\u0026rsquo;évolution des architectures d\u0026rsquo;applications Web :\u003c/p\u003e\n\u003cp\u003e\u003cimg\n  src=\"image.png\"\n  alt=\"évolution des architectures web\"\n  loading=\"lazy\"\n  decoding=\"async\"\n  class=\"full-width\"\n/\u003e\n\n\u003c/p\u003e\n\u003ch3 id=\"modèle-1--application-web-classique\"\u003eModèle 1 : application Web classique\u003c/h3\u003e\n\u003cp\u003eDans le premier schema, l\u0026rsquo;application Web est principalement exécutée côté serveur. Celui-ci envoie donc directement au navigateur les pages HTML, le CSS et éventuellement du JavaScript pour faire quelques comportement riches. Ensuite, à chaque action utilisateur nécessitant de nouvelles données, le serveur est interrogé et renvoie la nouvelle page HTML.\u003c/p\u003e\n\u003ch3 id=\"modèle-2--application-web-ajax\"\u003eModèle 2 : application Web AJAX\u003c/h3\u003e\n\u003cp\u003eLe deuxième schema introduit le pattern AJAX, pour Asynchronous Javascript And XML. apparu au milieu des années 2000 (voir l\u0026rsquo;article de Jesse James Garrett : \u003ca href=\"http://www.adaptivepath.com/ideas/ajax-new-approach-web-applications/\"\u003ehttp://www.adaptivepath.com/ideas/ajax-new-approach-web-applications/\u003c/a\u003e ).\u003c/p\u003e\n\u003cp\u003eCe principe d\u0026rsquo;architecture permet de rendre l\u0026rsquo;application plus réactive en réduisant les échanges entre le navigateur et le serveur : lorsqu\u0026rsquo;une action utilisateur engendre un appel client pour récupérer des nouvelles données, on ne va rafraîchir qu\u0026rsquo;une portion de l\u0026rsquo;écran et non plus toute la page. Le serveur va alors renvoyer seulement des fragments d\u0026rsquo;IHM. Cela nécessitait la mise en place d\u0026rsquo;outils JavaScript côté client pour gérer ces rafraîchissements partiels, que ce soit par exemple en utilisant la librairie jQuery et sa fonction $.ajax, ou en utilisant des outils plus intégrés aux plateformes serveurs comme Java Server Faces ou Google Web Toolkit pour Java.\u003c/p\u003e\n\u003cp\u003eCette architecture apportait plus de réactivité mais aussi plus de complexité. Les outils pour la mettre en place engendraient de nombreux écueils : l\u0026rsquo;\u003cstrong\u003eutilisation massive de jQuery rendait une application impossible à maintenir\u003c/strong\u003e sans mettre en place des règles d\u0026rsquo;architectures techniques précises et nécessitant de très fortes compétences (ce qu\u0026rsquo;offrent aujourd\u0026rsquo;hui les frameworks MV* comme Backbone JS ou AngularJS), et \u003cstrong\u003eles frameworks côté serveur comme JSF pour Java étaient trop lourds et trop complexes\u003c/strong\u003e malgré leur volonté apparente de simplifier les développements, induisant de nombreux bugs et problèmes de performances.\u003c/p\u003e\n\u003ch3 id=\"modèle-3--application-web-mv-côté-client\"\u003eModèle 3 : application Web MV* côté client\u003c/h3\u003e\n\u003cp\u003eLe troisième schéma représente la nouvelle architecture dont il est question ici : les \u003cem\u003e\u003cem\u003earchitectures MV\u003c/em\u003e côté client\u003c/em\u003e*. Le principe est ici en rupture avec les deux premières : cette fois le \u003cstrong\u003eserveur ne renvoie que des données brutes non mises en forme pour l\u0026rsquo;affichage. C\u0026rsquo;est côté client, dans le navigateur, que l\u0026rsquo;écran est généré.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eLe terme \u003cstrong\u003eMV\u003c/strong\u003e* se réfère au pattern MVC pour [http://fr.wikipedia.org/wiki/Mod%C3%A8le-vue-contr%C3%B4leur](\u003cstrong\u003eModèle Vue Contrôleur\u003c/strong\u003e), qui est très utilisé côté serveur pour découper les différentes problématiques de gestion des vues et des données. Nous utilisons de plus en plus le terme MV* pour les nouvelles architectures afin de montrer que l\u0026rsquo;implémentation dans les applications est souvent, par pragmatisme, un peu différente du MVC pur. Cela reste un débat d\u0026rsquo;expert\u0026hellip;\u003c/p\u003e\n\u003cp\u003eL\u0026rsquo;important dans cette nouvelle architecture est donc le \u003cstrong\u003edéplacement de toute la logique d\u0026rsquo;IHM du serveur vers le client\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eCette séparation des responsabilités entre le serveur et le client qui n\u0026rsquo;est pas une nouveauté en soi a été remise au goût du jour par les applications natives pour mobiles, consommant des API indépendantes des clients consommateurs. Les nouvelles architectures d\u0026rsquo;applications Web étendent ce choix aux applications Web.\u003c/p\u003e\n\u003cp\u003ePourquoi ces nouvelles architectures n\u0026rsquo;ont pas été mises en oeuvre plus tôt ?\nAu fond, le langage JavaScript existe depuis que le Web existe, le principe ne semble pas si révolutionnaire que ça surtout qu\u0026rsquo;il s\u0026rsquo;apparente fortement aux applications client-serveur classiques existant avant le Web, alors pourquoi ne pas avoir pensé à ces architectures plus tôt ?\u003c/p\u003e\n\u003cp\u003eLa réponse est simple : ce n\u0026rsquo;était pas possible, sauf à s\u0026rsquo;appeler Google !\u003c/p\u003e\n\u003cp\u003eEn effet, 2 facteurs bridaient les possibilités de développement JavaScript :\u003c/p\u003e\n\u003cp\u003eles capacités et les performances limitées des navigateurs\nle manque d\u0026rsquo;industrialisation du développement JavaScript\nLa fin des limitations des navigateurs\nLe premier point était évident jusqu\u0026rsquo;à l\u0026rsquo;arrivée des dernières version d\u0026rsquo;Internet Explorer 9 et encore plus Internet Explorer 10. Les lenteurs et les nombreux bugs des versions précédentes d\u0026rsquo;Internet Explorer interdisaient de déployer des applications utilisant massivement JavaScript.\u003c/p\u003e\n\u003cp\u003eSauf à disposer de la force de frappe d\u0026rsquo;une équipe d\u0026rsquo;ingénieurs Google, vouloir développer un Gmail dans Internet Explorer 6 n\u0026rsquo;était tout simplement pas réaliste.\u003c/p\u003e\n\u003cp\u003eCela a bien changé depuis que Firefox et encore plus Chrome ont bousculé le marché et que Microsoft a rattrapé son retard, comme le montre le graphique ci-dessous :\u003c/p\u003e\n\u003cp\u003e\u003cimg\n  src=\"image-1.png\"\n  alt=\"Résultats des navigateurs par-rapport au test de performances Javascript Sunspider\n\"\n  loading=\"lazy\"\n  decoding=\"async\"\n  class=\"full-width\"\n/\u003e\n\n\u003c/p\u003e\n\u003cp\u003eMontrant les résultats des tests de performances JavaScript Sunspider de différents navigateurs, ce schema illustre parfaitement la rupture qui est arrivée aux alentours de 2010, avec l\u0026rsquo;amélioration des performances d\u0026rsquo;Internet Explorer : \u003cstrong\u003eles performances entre IE 6 et IE8 à ce test ont été améliorées d\u0026rsquo;un facteur x25 en passant de 177000 ms à 7000 ms !\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eDepuis les performances continuent de s\u0026rsquo;améliorer sensiblement, et cela couplé aux nouvelles capacités des terminaux aussi bien mobiles que fixes permet d\u0026rsquo;utiliser le navigateurs pour autre chose que l\u0026rsquo;affichage de pages Web : générer les pages dynamiquement, faire du dessin 2D ou 3D, exécuter des algorithmes complexes, etc.\u003c/p\u003e\n\u003cp\u003eL\u0026rsquo;industrialisation du développement JavaScript\nAvoir une plateforme d\u0026rsquo;exécution puissante ne servirait à rien si on ne pouvait pas développer efficacement pour.\u003c/p\u003e\n\u003cp\u003eLa deuxième révolution technologique du développement Web concerne justement l\u0026rsquo;outillage de développement JavaScript.\u003c/p\u003e\n\u003cp\u003eSi vous suivez le blog OCTO, vous avez déjà pu voir passer des articles concernant par exemple \u003cstrong\u003eAngularJS\u003c/strong\u003e ou \u003cstrong\u003eGrunt\u003c/strong\u003e. Ce sont justement deux outils illustrant le nouvel écosystème de développement JavaScript, que l\u0026rsquo;on peut résumer en deux grandes familles d\u0026rsquo;outils :\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eles frameworks de développement\u003c/strong\u003e : là où on utilisait déjà des librairies comme jQuery, qui facilitaient certains développement en JavaScript, les développeurs disposent désormais de véritables frameworks permettant de structurer l\u0026rsquo;application. L\u0026rsquo;intérêt de ces frameworks est double : accélérer les développements et assurer une bonne maintenabilité du code. Parmi les plus connus aujourd\u0026rsquo;hui on trouve notamment AngularJS, BackboneJS et EmberJS.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eles outils d\u0026rsquo;industrialisation\u003c/strong\u003e : l\u0026rsquo;industrialisation des développements JavaScript a explosé ces deux dernières années, en s\u0026rsquo;inspirant fortement de ce qui a déjà été fait pour les autres plateformes comme Java. \u003cstrong\u003eDe la même manière que les développeurs Java utilisent Maven pour automatiser le build et les tests de leurs applications, les développeurs JavaScript peuvent aujourd\u0026rsquo;hui utiliser Grunt pour automatiser les tests et la construction de leur application\u003c/strong\u003e, ainsi que le workflow spécifique au développement front : concaténation des fichiers, obfuscation, minification, génération de sprites CSS, etc. L\u0026rsquo;ensemble de ces outils a déjà été abordé dans cet article du blog : \u003ca href=\"https://blog.octo.com/jenkins-pour-le-back-notepad-pour-le-front/\"\u003ehttps://blog.octo.com/jenkins-pour-le-back-notepad-pour-le-front/\u003c/a\u003e .\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eL\u0026rsquo;industrialisation du développement Javascript est par ailleurs poussée également par le fait que l\u0026rsquo;utilisation de Javascript s\u0026rsquo;étend à d\u0026rsquo;autres domaines que les applications Web, et notamment au développement serveur avec NodeJS. Cela d\u0026rsquo;autant plus frappant que NodeJS est utilisé comme socle technique par GruntJS et ses nombreux plug-ins.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eEn conclusion, tous les outils sont là en 2013 pour faire du développement JavaScript de manière efficace et industrielle.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eConclusion de la première partie\nDans cet article, nous avons présenté ce que l\u0026rsquo;on entend par \u0026ldquo;architectures MV* côté client\u0026rdquo;, et pourquoi elles émergent aujourd\u0026rsquo;hui.\u003c/p\u003e\n\u003cp\u003eDans les parties suivantes, \u003cstrong\u003enous verrons pourquoi il faut utiliser ces architectures dès aujourd\u0026rsquo;hui, quels sont les écueils à éviter et quels sont les impacts sur vos DSI.\u003c/strong\u003e\u003c/p\u003e\n",
      "url": "https://francoispetitit.com/posts/les-nouvelles-architectures-web-et-leur-impact-sur-les-dsi/",
      "date_published": "29106-29-09T1011:2929:00+02:00",
      "date_modified": "29106-29-09T1011:2929:00+02:00",
      "author": {
        "name": "François Petitit",
        "url": "https://francoispetitit.com/"
      }
    },
    
    {
      "id": "c919fa3e91246abacf6c5945fe7bbb0a71be85bd",
      "title": "Paris Web Atelier HTML5 Pour Mon Ordinateur Et Mon Mobile",
      "summary": "",
      "content_text": "In 2010, with my friend and former colleague Mickael Morier, I presented a workshop at Paris Web entitled \u0026ldquo;HTML5 for my computer and my mobile\u0026rdquo;.\n",
      "content_html": "\u003cp\u003eIn 2010, with my friend and former colleague Mickael Morier, I presented a workshop at \u003ca href=\"https://www.paris-web.fr/\"\u003eParis Web\u003c/a\u003e entitled \u0026ldquo;HTML5 for my computer and my mobile\u0026rdquo;.\u003c/p\u003e\n\u003ciframe src=\"http://www.dailymotion.com/embed/video/xh43oe?logo=0\" width=\"594\" height=\"475\" frameborder=\"0\"\u003e\u003c/iframe\u003e",
      "url": "https://francoispetitit.com/posts/paris-web-atelier-html5-pour-mon-ordinateur-et-mon-mobile/",
      "date_published": "10106-10-09T1046:1010:00+02:00",
      "date_modified": "10106-10-09T1046:1010:00+02:00",
      "author": {
        "name": "François Petitit",
        "url": "https://francoispetitit.com/"
      }
    }
    
  ]
}